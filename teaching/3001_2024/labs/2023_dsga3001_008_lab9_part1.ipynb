{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4Rj9dj1OFXT"
   },
   "source": [
    "## Lab 09\n",
    "## Disruptive Algorithms and Frameworks: DeepMind's AlphaZero and Acme\n",
    "\n",
    "#### Professor - Jeremy Curuksu, PhD (jeremy.cur@nyu.edu)\n",
    "\n",
    "#### Section Leader - Anudeep Tubati (at5373@nyu.edu)\n",
    "\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "Today, we will look at one of the most elegant algorithms in RL and the framework its creators use for day-to-day research. Personally, AlphaZero amazes me every single time I think about it. \n",
    "\n",
    "We will use Google Colab for today's lab since it does not have any pygame dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AXrXvBJOGBh",
    "outputId": "72a3153e-dc51-4725-975d-4f950c922018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: git+https://github.com/deepmind/acme.git#egg=dm-acme[jax,tf,envs] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting dm-acme[envs,jax,tf]\n",
      "  Cloning https://github.com/deepmind/acme.git to /tmp/pip-install-09rjwzmw/dm-acme_66d0aa0372e94e0fa395d3ff77238759\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/acme.git /tmp/pip-install-09rjwzmw/dm-acme_66d0aa0372e94e0fa395d3ff77238759\n",
      "  Resolved https://github.com/deepmind/acme.git to commit d1e69c92000079b118b868ce9303ee6d39c4a0b6\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (1.4.0)\n",
      "Collecting dm-env\n",
      "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.1.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (1.22.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (4.5.0)\n",
      "Requirement already satisfied: jax>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.4.7)\n",
      "Requirement already satisfied: chex in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.1.7)\n",
      "Collecting dm-haiku\n",
      "  Downloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flax in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.6.8)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.1.4)\n",
      "Collecting rlax\n",
      "  Downloading rlax-0.1.5-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow==2.8.0\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow_probability==0.15.0\n",
      "  Downloading tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow_datasets==4.6.0\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-reverb==0.7.2\n",
      "  Downloading dm_reverb-0.7.2-cp39-cp39-manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-launchpad==0.5.2\n",
      "  Downloading dm_launchpad-0.5.2-cp39-cp39-manylinux2014_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-sonnet\n",
      "  Downloading dm_sonnet-2.0.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.4/268.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trfl\n",
      "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting atari-py\n",
      "  Downloading atari_py-0.2.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bsuite\n",
      "  Downloading bsuite-0.3.5.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting dm-control\n",
      "  Downloading dm_control-1.0.11-py3-none-any.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gym==0.25.0\n",
      "  Downloading gym-0.25.0.tar.gz (720 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.9/dist-packages (from dm-acme[envs,jax,tf]) (0.25.2)\n",
      "Collecting pygame==2.1.0\n",
      "  Downloading pygame-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rlds\n",
      "  Downloading rlds-0.1.7-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: portpicker in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (1.3.9)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (1.53.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (2.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (5.9.4)\n",
      "Collecting mock\n",
      "  Downloading mock-5.0.1-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from dm-launchpad==0.5.2->dm-acme[envs,jax,tf]) (2.2.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym==0.25.0->dm-acme[envs,jax,tf]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.25.0->dm-acme[envs,jax,tf]) (6.2.0)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.32.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (1.16.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.4.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (3.8.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (23.3.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (67.6.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8.0->dm-acme[envs,jax,tf]) (16.0.0)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (1.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (4.65.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (1.13.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (2.3)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (0.10.2)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.15.0->dm-acme[envs,jax,tf]) (4.4.2)\n",
      "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.4.3->dm-acme[envs,jax,tf]) (1.10.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.4.3->dm-acme[envs,jax,tf]) (0.0.4)\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.9/dist-packages (from bsuite->dm-acme[envs,jax,tf]) (2.3.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from bsuite->dm-acme[envs,jax,tf]) (3.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from bsuite->dm-acme[envs,jax,tf]) (1.5.3)\n",
      "Requirement already satisfied: plotnine in /usr/local/lib/python3.9/dist-packages (from bsuite->dm-acme[envs,jax,tf]) (0.10.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from bsuite->dm-acme[envs,jax,tf]) (0.19.3)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.9/dist-packages (from chex->dm-acme[envs,jax,tf]) (0.4.7+cuda11.cudnn86)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex->dm-acme[envs,jax,tf]) (0.12.0)\n",
      "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from dm-control->dm-acme[envs,jax,tf]) (3.1.6)\n",
      "Collecting glfw\n",
      "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting labmaze\n",
      "  Downloading labmaze-1.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from dm-control->dm-acme[envs,jax,tf]) (4.9.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from dm-control->dm-acme[envs,jax,tf]) (3.0.9)\n",
      "Collecting mujoco>=2.3.3\n",
      "  Downloading mujoco-2.3.3-2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from dm-haiku->dm-acme[envs,jax,tf]) (0.8.10)\n",
      "Collecting jmp>=0.0.2\n",
      "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[envs,jax,tf]) (13.3.3)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[envs,jax,tf]) (0.1.35)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[envs,jax,tf]) (6.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[envs,jax,tf]) (1.0.5)\n",
      "Requirement already satisfied: orbax in /usr/local/lib/python3.9/dist-packages (from flax->dm-acme[envs,jax,tf]) (0.1.7)\n",
      "Collecting gym[atari]\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Downloading gym-0.26.1.tar.gz (719 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.9/719.9 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Downloading gym-0.26.0.tar.gz (710 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m710.3/710.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Downloading gym-0.25.1.tar.gz (732 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.2/732.2 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting ale-py~=0.7.5\n",
      "  Downloading ale_py-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distrax>=0.0.2\n",
      "  Downloading distrax-0.1.3-py3-none-any.whl (317 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.0/318.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.7.5->gym==0.25.0->dm-acme[envs,jax,tf]) (5.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.40.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym==0.25.0->dm-acme[envs,jax,tf]) (3.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (3.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax->dm-acme[envs,jax,tf]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax->dm-acme[envs,jax,tf]) (2.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (2.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (3.4.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (2.2.3)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (1.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (4.39.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bsuite->dm-acme[envs,jax,tf]) (2.8.2)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[envs,jax,tf]) (1.5.6)\n",
      "Requirement already satisfied: cached_property in /usr/local/lib/python3.9/dist-packages (from orbax->flax->dm-acme[envs,jax,tf]) (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->bsuite->dm-acme[envs,jax,tf]) (2022.7.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from plotnine->bsuite->dm-acme[envs,jax,tf]) (0.13.5)\n",
      "Requirement already satisfied: mizani>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from plotnine->bsuite->dm-acme[envs,jax,tf]) (0.8.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from plotnine->bsuite->dm-acme[envs,jax,tf]) (0.5.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->bsuite->dm-acme[envs,jax,tf]) (2.25.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->bsuite->dm-acme[envs,jax,tf]) (3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->bsuite->dm-acme[envs,jax,tf]) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->bsuite->dm-acme[envs,jax,tf]) (2023.3.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0->dm-acme[envs,jax,tf]) (1.59.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax->dm-acme[envs,jax,tf]) (0.1.2)\n",
      "Requirement already satisfied: palettable in /usr/local/lib/python3.9/dist-packages (from mizani>=0.8.1->plotnine->bsuite->dm-acme[envs,jax,tf]) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->dm-acme[envs,jax,tf]) (3.2.2)\n",
      "Building wheels for collected packages: gym, bsuite, dm-acme\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.25.0-py3-none-any.whl size=824432 sha256=177efff51f9c09e9e5d8648c7c95f8ea5c8288a77c2f86758850e1cab7553a86\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/e9/eb/09deaeab0e9d75b97bced465f29be68ed4afde208e65649660\n",
      "  Building wheel for bsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bsuite: filename=bsuite-0.3.5-py3-none-any.whl size=245536 sha256=4706b14e9c196303b74b3595d6a2099e3e5cb481acc80dd5b13231c6ab8b54e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/73/d4/93/6644ba37562f60dd9b77069e7949e0b474c2817e2173b6a46b\n",
      "  Building wheel for dm-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dm-acme: filename=dm_acme-0.4.1-py3-none-any.whl size=824552 sha256=4dd3e25567ff816b54935197820747b8933ff113bbb82cf1527289286772998f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l2_600xe/wheels/81/10/f3/4630005664991ea748d1f45c9770cc3b2cc332cda86131ff54\n",
      "Successfully built gym bsuite dm-acme\n",
      "Installing collected packages: tf-estimator-nightly, keras, glfw, trfl, tensorflow_probability, tensorboard-data-server, rlds, pygame, mujoco, mock, labmaze, keras-preprocessing, jmp, dm-sonnet, dm-reverb, dm-env, dill, atari-py, gym, dm-launchpad, dm-haiku, dm-control, dm-acme, ale-py, tensorflow_datasets, google-auth-oauthlib, tensorboard, distrax, tensorflow, rlax, bsuite\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorflow_probability\n",
      "    Found existing installation: tensorflow-probability 0.19.0\n",
      "    Uninstalling tensorflow-probability-0.19.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.19.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.3.0\n",
      "    Uninstalling pygame-2.3.0:\n",
      "      Successfully uninstalled pygame-2.3.0\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.25.2\n",
      "    Uninstalling gym-0.25.2:\n",
      "      Successfully uninstalled gym-0.25.2\n",
      "  Attempting uninstall: tensorflow_datasets\n",
      "    Found existing installation: tensorflow-datasets 4.8.3\n",
      "    Uninstalling tensorflow-datasets-4.8.3:\n",
      "      Successfully uninstalled tensorflow-datasets-4.8.3\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.1\n",
      "    Uninstalling tensorboard-2.12.1:\n",
      "      Successfully uninstalled tensorboard-2.12.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed ale-py-0.7.5 atari-py-0.2.9 bsuite-0.3.5 dill-0.3.6 distrax-0.1.3 dm-acme-0.4.1 dm-control-1.0.11 dm-env-1.6 dm-haiku-0.0.9 dm-launchpad-0.5.2 dm-reverb-0.7.2 dm-sonnet-2.0.1 glfw-2.5.9 google-auth-oauthlib-0.4.6 gym-0.25.0 jmp-0.0.4 keras-2.8.0 keras-preprocessing-1.1.2 labmaze-1.0.6 mock-5.0.1 mujoco-2.3.3 pygame-2.1.0 rlax-0.1.5 rlds-0.1.7 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorflow-2.8.0 tensorflow_datasets-4.6.0 tensorflow_probability-0.15.0 tf-estimator-nightly-2.8.0.dev2021122109 trfl-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# lets install the Acme framework\n",
    "!pip install git+https://github.com/deepmind/acme.git#egg=dm-acme[jax,tf,envs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HyGWZ-3OFXX",
    "outputId": "d8aabeee-784e-45c0-f34f-9a6a15123a51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "import dm_env\n",
    "import acme\n",
    "from acme import wrappers\n",
    "from acme import specs\n",
    "from acme.tf import networks\n",
    "from acme.tf import utils as tf2_utils\n",
    "from acme.agents.tf import dqn\n",
    "from acme.utils import loggers\n",
    "\n",
    "import sonnet as snt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # help with seeing ACME logs\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BgA98UDkOFXa"
   },
   "outputs": [],
   "source": [
    "def make_environment(level: str = \"CartPole-v1\",\n",
    "                     record: bool = False) -> dm_env.Environment:\n",
    "    environment = gym.make(level)\n",
    "    if record:\n",
    "        environment = RecordVideo(environment, \"./video\", )\n",
    "\n",
    "    environment = wrappers.GymWrapper(environment)\n",
    "    environment = wrappers.SinglePrecisionWrapper(environment)\n",
    "\n",
    "    return environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ71jxnlOFXb",
    "outputId": "2276f313-7dd2-4ce4-f53c-8503fee62479"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.001 | Env Step Duration Sec = 0.000 | Episode Duration = 0.289 | Episode Length = 9 | Episode Return = 9.0 | Episodes = 1 | Select Action Duration Sec = 0.026 | Steps = 9 | Steps Per Second = 31.152\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.037 | Episode Length = 10 | Episode Return = 10.0 | Episodes = 25 | Select Action Duration Sec = 0.002 | Steps = 296 | Steps Per Second = 270.154\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.037 | Episode Length = 16 | Episode Return = 16.0 | Episodes = 51 | Select Action Duration Sec = 0.001 | Steps = 663 | Steps Per Second = 436.339\n",
      "INFO:tensorflow:Assets written to: /root/acme/20230412-205733/snapshots/network/assets\n",
      "INFO:root:[Learner] Loss = 0.343 | Steps = 1 | Walltime = 0\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.986 | Episode Length = 17 | Episode Return = 17.0 | Episodes = 81 | Select Action Duration Sec = 0.001 | Steps = 1002 | Steps Per Second = 17.236\n",
      "INFO:root:[Learner] Loss = 0.319 | Steps = 167 | Walltime = 1.206\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.085 | Episode Length = 12 | Episode Return = 12.0 | Episodes = 95 | Select Action Duration Sec = 0.002 | Steps = 1178 | Steps Per Second = 141.220\n",
      "INFO:root:[Learner] Loss = 0.141 | Steps = 325 | Walltime = 2.207\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.249 | Episode Length = 42 | Episode Return = 42.0 | Episodes = 104 | Select Action Duration Sec = 0.001 | Steps = 1347 | Steps Per Second = 168.502\n",
      "INFO:root:[Learner] Loss = 0.205 | Steps = 486 | Walltime = 3.212\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.416 | Episode Length = 73 | Episode Return = 73.0 | Episodes = 109 | Select Action Duration Sec = 0.001 | Steps = 1580 | Steps Per Second = 175.412\n",
      "INFO:root:[Learner] Loss = 0.285 | Steps = 657 | Walltime = 4.216\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.767 | Episode Length = 136 | Episode Return = 136.0 | Episodes = 111 | Select Action Duration Sec = 0.001 | Steps = 1810 | Steps Per Second = 177.315\n",
      "INFO:root:[Learner] Loss = 0.282 | Steps = 831 | Walltime = 5.221\n",
      "INFO:root:[Learner] Loss = 0.491 | Steps = 983 | Walltime = 6.228\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.288 | Episode Length = 188 | Episode Return = 188.0 | Episodes = 112 | Select Action Duration Sec = 0.001 | Steps = 1998 | Steps Per Second = 145.997\n",
      "INFO:root:[Learner] Loss = 0.650 | Steps = 1096 | Walltime = 7.236\n",
      "INFO:root:[Learner] Loss = 0.311 | Steps = 1167 | Walltime = 8.237\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.375 | Episode Length = 200 | Episode Return = 200.0 | Episodes = 113 | Select Action Duration Sec = 0.002 | Steps = 2198 | Steps Per Second = 84.232\n",
      "INFO:root:[Learner] Loss = 0.265 | Steps = 1221 | Walltime = 9.240\n",
      "INFO:root:[Learner] Loss = 0.235 | Steps = 1278 | Walltime = 10.243\n",
      "INFO:root:[Learner] Loss = 0.380 | Steps = 1333 | Walltime = 11.246\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.244 | Episode Length = 181 | Episode Return = 181.0 | Episodes = 114 | Select Action Duration Sec = 0.004 | Steps = 2379 | Steps Per Second = 55.806\n",
      "INFO:root:[Learner] Loss = 0.281 | Steps = 1392 | Walltime = 12.265\n",
      "INFO:root:[Learner] Loss = 0.287 | Steps = 1452 | Walltime = 13.265\n",
      "INFO:root:[Learner] Loss = 0.458 | Steps = 1505 | Walltime = 14.282\n",
      "INFO:root:[Learner] Loss = 0.095 | Steps = 1573 | Walltime = 15.285\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.342 | Episode Length = 203 | Episode Return = 203.0 | Episodes = 115 | Select Action Duration Sec = 0.004 | Steps = 2582 | Steps Per Second = 60.753\n",
      "INFO:root:[Learner] Loss = 0.099 | Steps = 1653 | Walltime = 16.292\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.467 | Episode Length = 136 | Episode Return = 136.0 | Episodes = 116 | Select Action Duration Sec = 0.002 | Steps = 2718 | Steps Per Second = 92.734\n",
      "INFO:root:[Learner] Loss = 0.056 | Steps = 1775 | Walltime = 17.298\n",
      "INFO:root:[Learner] Loss = 0.113 | Steps = 1852 | Walltime = 18.311\n",
      "INFO:root:[Learner] Loss = 0.072 | Steps = 1956 | Walltime = 19.314\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.993 | Episode Length = 302 | Episode Return = 302.0 | Episodes = 117 | Select Action Duration Sec = 0.002 | Steps = 3020 | Steps Per Second = 100.923\n",
      "INFO:root:[Learner] Loss = 0.068 | Steps = 2067 | Walltime = 20.333\n",
      "INFO:root:[Learner] Loss = 0.100 | Steps = 2143 | Walltime = 21.340\n",
      "INFO:root:[Learner] Loss = 0.118 | Steps = 2245 | Walltime = 22.351\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.101 | Episode Length = 300 | Episode Return = 300.0 | Episodes = 118 | Select Action Duration Sec = 0.002 | Steps = 3320 | Steps Per Second = 96.741\n",
      "INFO:root:[Learner] Loss = 0.149 | Steps = 2367 | Walltime = 23.351\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.327 | Episode Length = 187 | Episode Return = 187.0 | Episodes = 119 | Select Action Duration Sec = 0.001 | Steps = 3507 | Steps Per Second = 140.904\n",
      "INFO:root:[Learner] Loss = 0.206 | Steps = 2520 | Walltime = 24.353\n",
      "INFO:root:[Learner] Loss = 0.266 | Steps = 2691 | Walltime = 25.358\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.890 | Episode Length = 157 | Episode Return = 157.0 | Episodes = 121 | Select Action Duration Sec = 0.001 | Steps = 3830 | Steps Per Second = 176.489\n",
      "INFO:root:[Learner] Loss = 0.072 | Steps = 2863 | Walltime = 26.362\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.110 | Episode Length = 172 | Episode Return = 172.0 | Episodes = 122 | Select Action Duration Sec = 0.001 | Steps = 4002 | Steps Per Second = 154.958\n",
      "INFO:root:[Learner] Loss = 0.127 | Steps = 3016 | Walltime = 27.368\n",
      "INFO:root:[Learner] Loss = 0.135 | Steps = 3116 | Walltime = 28.375\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.001 | Env Step Duration Sec = 0.000 | Episode Duration = 1.347 | Episode Length = 151 | Episode Return = 151.0 | Episodes = 123 | Select Action Duration Sec = 0.002 | Steps = 4153 | Steps Per Second = 112.138\n",
      "INFO:root:[Learner] Loss = 0.089 | Steps = 3252 | Walltime = 29.378\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.209 | Episode Length = 145 | Episode Return = 145.0 | Episodes = 124 | Select Action Duration Sec = 0.002 | Steps = 4298 | Steps Per Second = 119.907\n",
      "INFO:root:[Learner] Loss = 0.028 | Steps = 3340 | Walltime = 30.382\n",
      "INFO:root:[Learner] Loss = 0.025 | Steps = 3418 | Walltime = 31.399\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.215 | Episode Length = 149 | Episode Return = 149.0 | Episodes = 125 | Select Action Duration Sec = 0.003 | Steps = 4447 | Steps Per Second = 67.279\n",
      "INFO:root:[Learner] Loss = 0.026 | Steps = 3471 | Walltime = 32.406\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 3543 | Walltime = 33.406\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.080 | Episode Length = 163 | Episode Return = 163.0 | Episodes = 126 | Select Action Duration Sec = 0.002 | Steps = 4610 | Steps Per Second = 78.384\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 3644 | Walltime = 34.408\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 3731 | Walltime = 35.414\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.667 | Episode Length = 168 | Episode Return = 168.0 | Episodes = 127 | Select Action Duration Sec = 0.002 | Steps = 4778 | Steps Per Second = 100.790\n",
      "INFO:root:[Learner] Loss = 0.040 | Steps = 3854 | Walltime = 36.416\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.204 | Episode Length = 142 | Episode Return = 142.0 | Episodes = 128 | Select Action Duration Sec = 0.002 | Steps = 4920 | Steps Per Second = 117.985\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 3969 | Walltime = 37.423\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.345 | Episode Length = 155 | Episode Return = 155.0 | Episodes = 129 | Select Action Duration Sec = 0.002 | Steps = 5075 | Steps Per Second = 115.304\n",
      "INFO:root:[Learner] Loss = 0.025 | Steps = 4082 | Walltime = 38.431\n",
      "INFO:root:[Learner] Loss = 0.015 | Steps = 4201 | Walltime = 39.434\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.511 | Episode Length = 178 | Episode Return = 178.0 | Episodes = 130 | Select Action Duration Sec = 0.002 | Steps = 5253 | Steps Per Second = 117.844\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 4305 | Walltime = 40.438\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 4405 | Walltime = 41.443\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.809 | Episode Length = 194 | Episode Return = 194.0 | Episodes = 131 | Select Action Duration Sec = 0.002 | Steps = 5447 | Steps Per Second = 107.231\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 4579 | Walltime = 42.451\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.003 | Episode Length = 175 | Episode Return = 175.0 | Episodes = 132 | Select Action Duration Sec = 0.001 | Steps = 5622 | Steps Per Second = 174.456\n",
      "INFO:root:[Learner] Loss = 0.026 | Steps = 4755 | Walltime = 43.451\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.221 | Episode Length = 218 | Episode Return = 218.0 | Episodes = 133 | Select Action Duration Sec = 0.001 | Steps = 5840 | Steps Per Second = 178.606\n",
      "INFO:root:[Learner] Loss = 0.015 | Steps = 4932 | Walltime = 44.454\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 5119 | Walltime = 45.456\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 5302 | Walltime = 46.461\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.769 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 134 | Select Action Duration Sec = 0.001 | Steps = 6340 | Steps Per Second = 180.567\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 5477 | Walltime = 47.466\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.001 | Env Step Duration Sec = 0.000 | Episode Duration = 1.365 | Episode Length = 244 | Episode Return = 244.0 | Episodes = 135 | Select Action Duration Sec = 0.001 | Steps = 6584 | Steps Per Second = 178.730\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 5649 | Walltime = 48.470\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.390 | Episode Length = 240 | Episode Return = 240.0 | Episodes = 136 | Select Action Duration Sec = 0.001 | Steps = 6824 | Steps Per Second = 172.698\n",
      "INFO:root:[Learner] Loss = 0.156 | Steps = 5826 | Walltime = 49.471\n",
      "INFO:root:[Learner] Loss = 0.175 | Steps = 6004 | Walltime = 50.473\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.118 | Episode Length = 19 | Episode Return = 19.0 | Episodes = 138 | Select Action Duration Sec = 0.001 | Steps = 7006 | Steps Per Second = 160.537\n",
      "INFO:root:[Learner] Loss = 0.251 | Steps = 6166 | Walltime = 51.477\n",
      "INFO:root:[Learner] Loss = 0.357 | Steps = 6286 | Walltime = 52.482\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.161 | Episode Length = 301 | Episode Return = 301.0 | Episodes = 139 | Select Action Duration Sec = 0.002 | Steps = 7307 | Steps Per Second = 139.277\n",
      "INFO:root:[Learner] Loss = 0.255 | Steps = 6409 | Walltime = 53.486\n",
      "INFO:root:[Learner] Loss = 0.207 | Steps = 6532 | Walltime = 54.491\n",
      "INFO:root:[Learner] Loss = 0.178 | Steps = 6650 | Walltime = 55.493\n",
      "INFO:root:[Learner] Loss = 0.181 | Steps = 6768 | Walltime = 56.494\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.167 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 140 | Select Action Duration Sec = 0.002 | Steps = 7807 | Steps Per Second = 120.001\n",
      "INFO:root:[Learner] Loss = 0.223 | Steps = 6891 | Walltime = 57.500\n",
      "INFO:root:[Learner] Loss = 0.217 | Steps = 7015 | Walltime = 58.503\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 7137 | Walltime = 59.508\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.200 | Episode Length = 391 | Episode Return = 391.0 | Episodes = 141 | Select Action Duration Sec = 0.002 | Steps = 8198 | Steps Per Second = 122.214\n",
      "INFO:root:[Learner] Loss = 0.028 | Steps = 7252 | Walltime = 60.512\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 7374 | Walltime = 61.518\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 7546 | Walltime = 62.522\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.351 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 142 | Select Action Duration Sec = 0.001 | Steps = 8698 | Steps Per Second = 149.199\n",
      "INFO:root:[Learner] Loss = 0.031 | Steps = 7723 | Walltime = 63.526\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 7900 | Walltime = 64.530\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.515 | Episode Length = 264 | Episode Return = 264.0 | Episodes = 143 | Select Action Duration Sec = 0.001 | Steps = 8962 | Steps Per Second = 174.263\n",
      "INFO:root:[Learner] Loss = 0.125 | Steps = 8075 | Walltime = 65.534\n",
      "INFO:root:[Learner] Loss = 0.065 | Steps = 8254 | Walltime = 66.534\n",
      "INFO:root:[Learner] Loss = 0.028 | Steps = 8437 | Walltime = 67.540\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.786 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 144 | Select Action Duration Sec = 0.001 | Steps = 9462 | Steps Per Second = 179.460\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 8610 | Walltime = 68.545\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 8783 | Walltime = 69.545\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.958 | Episode Length = 339 | Episode Return = 339.0 | Episodes = 145 | Select Action Duration Sec = 0.001 | Steps = 9801 | Steps Per Second = 173.126\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 8956 | Walltime = 70.547\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 9137 | Walltime = 71.556\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 9196 | Walltime = 72.557\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.783 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 146 | Select Action Duration Sec = 0.002 | Steps = 10301 | Steps Per Second = 132.173\n",
      "INFO:root:[Learner] Loss = 0.011 | Steps = 9316 | Walltime = 73.560\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 9439 | Walltime = 74.563\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.672 | Episode Length = 202 | Episode Return = 202.0 | Episodes = 147 | Select Action Duration Sec = 0.002 | Steps = 10503 | Steps Per Second = 120.825\n",
      "INFO:root:[Learner] Loss = 0.352 | Steps = 9555 | Walltime = 75.569\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.015 | Episode Length = 121 | Episode Return = 121.0 | Episodes = 148 | Select Action Duration Sec = 0.002 | Steps = 10624 | Steps Per Second = 119.227\n",
      "INFO:root:[Learner] Loss = 0.674 | Steps = 9676 | Walltime = 76.572\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.072 | Episode Length = 125 | Episode Return = 125.0 | Episodes = 149 | Select Action Duration Sec = 0.002 | Steps = 10749 | Steps Per Second = 116.578\n",
      "INFO:root:[Learner] Loss = 0.551 | Steps = 9789 | Walltime = 77.578\n",
      "INFO:root:[Learner] Loss = 0.510 | Steps = 9907 | Walltime = 78.586\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.271 | Episode Length = 153 | Episode Return = 153.0 | Episodes = 151 | Select Action Duration Sec = 0.002 | Steps = 10992 | Steps Per Second = 120.363\n",
      "INFO:root:[Learner] Loss = 0.654 | Steps = 10032 | Walltime = 79.592\n",
      "INFO:root:[Learner] Loss = 0.584 | Steps = 10150 | Walltime = 80.599\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.887 | Episode Length = 226 | Episode Return = 226.0 | Episodes = 152 | Select Action Duration Sec = 0.002 | Steps = 11218 | Steps Per Second = 119.767\n",
      "INFO:root:[Learner] Loss = 0.442 | Steps = 10271 | Walltime = 81.602\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.418 | Episode Length = 207 | Episode Return = 207.0 | Episodes = 153 | Select Action Duration Sec = 0.001 | Steps = 11425 | Steps Per Second = 146.010\n",
      "INFO:root:[Learner] Loss = 0.820 | Steps = 10427 | Walltime = 82.606\n",
      "INFO:root:[Learner] Loss = 0.359 | Steps = 10603 | Walltime = 83.609\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.731 | Episode Length = 135 | Episode Return = 135.0 | Episodes = 155 | Select Action Duration Sec = 0.001 | Steps = 11730 | Steps Per Second = 184.627\n",
      "INFO:root:[Learner] Loss = 0.164 | Steps = 10787 | Walltime = 84.610\n",
      "INFO:root:[Learner] Loss = 0.115 | Steps = 10965 | Walltime = 85.615\n",
      "INFO:root:[Learner] Loss = 0.078 | Steps = 11137 | Walltime = 86.619\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.357 | Episode Length = 411 | Episode Return = 411.0 | Episodes = 156 | Select Action Duration Sec = 0.001 | Steps = 12141 | Steps Per Second = 174.399\n",
      "INFO:root:[Learner] Loss = 0.147 | Steps = 11311 | Walltime = 87.622\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.527 | Episode Length = 270 | Episode Return = 270.0 | Episodes = 157 | Select Action Duration Sec = 0.001 | Steps = 12411 | Steps Per Second = 176.867\n",
      "INFO:root:[Learner] Loss = 0.099 | Steps = 11489 | Walltime = 88.625\n",
      "INFO:root:[Learner] Loss = 0.290 | Steps = 11669 | Walltime = 89.626\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.973 | Episode Length = 349 | Episode Return = 349.0 | Episodes = 158 | Select Action Duration Sec = 0.001 | Steps = 12760 | Steps Per Second = 176.899\n",
      "INFO:root:[Learner] Loss = 0.116 | Steps = 11840 | Walltime = 90.632\n",
      "INFO:root:[Learner] Loss = 0.122 | Steps = 12006 | Walltime = 91.632\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.324 | Episode Length = 378 | Episode Return = 378.0 | Episodes = 159 | Select Action Duration Sec = 0.001 | Steps = 13138 | Steps Per Second = 162.651\n",
      "INFO:root:[Learner] Loss = 0.041 | Steps = 12158 | Walltime = 92.635\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 12283 | Walltime = 93.637\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 12411 | Walltime = 94.643\n",
      "INFO:root:[Learner] Loss = 0.032 | Steps = 12533 | Walltime = 95.648\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.997 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 160 | Select Action Duration Sec = 0.002 | Steps = 13638 | Steps Per Second = 125.106\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 12658 | Walltime = 96.654\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 12783 | Walltime = 97.656\n",
      "INFO:root:[Learner] Loss = 0.027 | Steps = 12902 | Walltime = 98.657\n",
      "INFO:root:[Learner] Loss = 0.028 | Steps = 13015 | Walltime = 99.658\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 13128 | Walltime = 100.664\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.256 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 161 | Select Action Duration Sec = 0.002 | Steps = 14138 | Steps Per Second = 117.500\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 13245 | Walltime = 101.668\n",
      "INFO:root:[Learner] Loss = 0.028 | Steps = 13371 | Walltime = 102.673\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 13545 | Walltime = 103.682\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.464 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 162 | Select Action Duration Sec = 0.001 | Steps = 14638 | Steps Per Second = 144.332\n",
      "INFO:root:[Learner] Loss = 0.020 | Steps = 13717 | Walltime = 104.683\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 13895 | Walltime = 105.686\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 14079 | Walltime = 106.689\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.813 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 163 | Select Action Duration Sec = 0.001 | Steps = 15138 | Steps Per Second = 177.756\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 14254 | Walltime = 107.691\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 14437 | Walltime = 108.695\n",
      "INFO:root:[Learner] Loss = 0.003 | Steps = 14632 | Walltime = 109.699\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.709 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 164 | Select Action Duration Sec = 0.001 | Steps = 15638 | Steps Per Second = 184.603\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 14815 | Walltime = 110.702\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 15002 | Walltime = 111.705\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.690 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 165 | Select Action Duration Sec = 0.001 | Steps = 16138 | Steps Per Second = 185.886\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 15176 | Walltime = 112.714\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 15297 | Walltime = 113.719\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 15329 | Walltime = 114.733\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 15425 | Walltime = 115.736\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.604 | Episode Length = 322 | Episode Return = 322.0 | Episodes = 166 | Select Action Duration Sec = 0.002 | Steps = 16460 | Steps Per Second = 89.360\n",
      "INFO:root:[Learner] Loss = 0.165 | Steps = 15545 | Walltime = 116.737\n",
      "INFO:root:[Learner] Loss = 0.198 | Steps = 15666 | Walltime = 117.742\n",
      "INFO:root:[Learner] Loss = 0.201 | Steps = 15783 | Walltime = 118.745\n",
      "INFO:root:[Learner] Loss = 0.161 | Steps = 15900 | Walltime = 119.750\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.751 | Episode Length = 444 | Episode Return = 444.0 | Episodes = 167 | Select Action Duration Sec = 0.002 | Steps = 16904 | Steps Per Second = 118.393\n",
      "INFO:root:[Learner] Loss = 0.581 | Steps = 16016 | Walltime = 120.753\n",
      "INFO:root:[Learner] Loss = 0.347 | Steps = 16141 | Walltime = 121.761\n",
      "INFO:root:[Learner] Loss = 0.595 | Steps = 16271 | Walltime = 122.770\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.850 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 168 | Select Action Duration Sec = 0.002 | Steps = 17404 | Steps Per Second = 129.886\n",
      "INFO:root:[Learner] Loss = 0.248 | Steps = 16425 | Walltime = 123.772\n",
      "INFO:root:[Learner] Loss = 0.070 | Steps = 16605 | Walltime = 124.775\n",
      "INFO:root:[Learner] Loss = 0.019 | Steps = 16789 | Walltime = 125.780\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.790 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 169 | Select Action Duration Sec = 0.001 | Steps = 17904 | Steps Per Second = 179.222\n",
      "INFO:root:[Learner] Loss = 0.011 | Steps = 16967 | Walltime = 126.784\n",
      "INFO:root:[Learner] Loss = 0.011 | Steps = 17146 | Walltime = 127.784\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 17331 | Walltime = 128.787\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.767 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 170 | Select Action Duration Sec = 0.001 | Steps = 18404 | Steps Per Second = 180.719\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 17507 | Walltime = 129.790\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 17684 | Walltime = 130.794\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 17873 | Walltime = 131.797\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.774 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 171 | Select Action Duration Sec = 0.001 | Steps = 18904 | Steps Per Second = 180.290\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 18053 | Walltime = 132.799\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 18193 | Walltime = 133.805\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 18314 | Walltime = 134.810\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.568 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 172 | Select Action Duration Sec = 0.001 | Steps = 19404 | Steps Per Second = 140.136\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 18435 | Walltime = 135.820\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 18561 | Walltime = 136.825\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 18669 | Walltime = 137.844\n",
      "INFO:root:[Learner] Loss = 0.023 | Steps = 18746 | Walltime = 138.869\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 18841 | Walltime = 139.870\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.845 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 173 | Select Action Duration Sec = 0.002 | Steps = 19904 | Steps Per Second = 103.207\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 18959 | Walltime = 140.871\n",
      "INFO:root:[Learner] Loss = 0.035 | Steps = 19083 | Walltime = 141.875\n",
      "INFO:root:[Learner] Loss = 0.019 | Steps = 19205 | Walltime = 142.877\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 19340 | Walltime = 143.878\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.860 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 174 | Select Action Duration Sec = 0.002 | Steps = 20404 | Steps Per Second = 129.549\n",
      "INFO:root:[Learner] Loss = 0.011 | Steps = 19510 | Walltime = 144.881\n",
      "INFO:root:[Learner] Loss = 0.039 | Steps = 19683 | Walltime = 145.883\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 19865 | Walltime = 146.884\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.849 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 175 | Select Action Duration Sec = 0.001 | Steps = 20904 | Steps Per Second = 175.515\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 20043 | Walltime = 147.887\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 20221 | Walltime = 148.890\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 20404 | Walltime = 149.897\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.782 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 176 | Select Action Duration Sec = 0.001 | Steps = 21404 | Steps Per Second = 179.719\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 20574 | Walltime = 150.901\n",
      "INFO:root:[Learner] Loss = 0.017 | Steps = 20721 | Walltime = 151.906\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 20871 | Walltime = 152.911\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.197 | Episode Length = 499 | Episode Return = 499.0 | Episodes = 177 | Select Action Duration Sec = 0.001 | Steps = 21903 | Steps Per Second = 156.095\n",
      "INFO:root:[Learner] Loss = 0.020 | Steps = 21024 | Walltime = 153.921\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.374 | Episode Length = 191 | Episode Return = 191.0 | Episodes = 178 | Select Action Duration Sec = 0.001 | Steps = 22094 | Steps Per Second = 139.003\n",
      "INFO:root:[Learner] Loss = 0.251 | Steps = 21149 | Walltime = 154.929\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.655 | Episode Length = 76 | Episode Return = 76.0 | Episodes = 180 | Select Action Duration Sec = 0.002 | Steps = 22242 | Steps Per Second = 116.008\n",
      "INFO:root:[Learner] Loss = 0.199 | Steps = 21267 | Walltime = 155.932\n",
      "INFO:root:[Learner] Loss = 0.404 | Steps = 21389 | Walltime = 156.933\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.659 | Episode Length = 202 | Episode Return = 202.0 | Episodes = 181 | Select Action Duration Sec = 0.002 | Steps = 22444 | Steps Per Second = 121.810\n",
      "INFO:root:[Learner] Loss = 0.802 | Steps = 21512 | Walltime = 157.936\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.359 | Episode Length = 161 | Episode Return = 161.0 | Episodes = 182 | Select Action Duration Sec = 0.002 | Steps = 22605 | Steps Per Second = 118.464\n",
      "INFO:root:[Learner] Loss = 0.745 | Steps = 21627 | Walltime = 158.937\n",
      "INFO:root:[Learner] Loss = 0.646 | Steps = 21747 | Walltime = 159.945\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.589 | Episode Length = 188 | Episode Return = 188.0 | Episodes = 183 | Select Action Duration Sec = 0.002 | Steps = 22793 | Steps Per Second = 118.301\n",
      "INFO:root:[Learner] Loss = 0.591 | Steps = 21861 | Walltime = 160.948\n",
      "INFO:root:[Learner] Loss = 0.310 | Steps = 21982 | Walltime = 161.952\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.683 | Episode Length = 197 | Episode Return = 197.0 | Episodes = 184 | Select Action Duration Sec = 0.002 | Steps = 22990 | Steps Per Second = 117.090\n",
      "INFO:root:[Learner] Loss = 0.317 | Steps = 22106 | Walltime = 162.960\n",
      "INFO:root:[Learner] Loss = 0.213 | Steps = 22227 | Walltime = 163.961\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.680 | Episode Length = 302 | Episode Return = 302.0 | Episodes = 185 | Select Action Duration Sec = 0.002 | Steps = 23292 | Steps Per Second = 112.702\n",
      "INFO:root:[Learner] Loss = 0.118 | Steps = 22335 | Walltime = 164.962\n",
      "INFO:root:[Learner] Loss = 0.149 | Steps = 22448 | Walltime = 165.964\n",
      "INFO:root:[Learner] Loss = 0.146 | Steps = 22624 | Walltime = 166.966\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.231 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 186 | Select Action Duration Sec = 0.001 | Steps = 23792 | Steps Per Second = 154.743\n",
      "INFO:root:[Learner] Loss = 0.119 | Steps = 22794 | Walltime = 167.971\n",
      "INFO:root:[Learner] Loss = 0.066 | Steps = 22970 | Walltime = 168.975\n",
      "INFO:root:[Learner] Loss = 0.064 | Steps = 23154 | Walltime = 169.980\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.825 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 187 | Select Action Duration Sec = 0.001 | Steps = 24292 | Steps Per Second = 176.996\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 23326 | Walltime = 170.984\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 23500 | Walltime = 171.986\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 23677 | Walltime = 172.986\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.854 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 188 | Select Action Duration Sec = 0.001 | Steps = 24792 | Steps Per Second = 175.188\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 23849 | Walltime = 173.993\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 23971 | Walltime = 174.998\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 24091 | Walltime = 176.000\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 24215 | Walltime = 177.006\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.032 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 189 | Select Action Duration Sec = 0.002 | Steps = 25292 | Steps Per Second = 124.028\n",
      "INFO:root:[Learner] Loss = 0.003 | Steps = 24331 | Walltime = 178.013\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 24453 | Walltime = 179.020\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 24576 | Walltime = 180.020\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 24689 | Walltime = 181.032\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.319 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 190 | Select Action Duration Sec = 0.002 | Steps = 25792 | Steps Per Second = 115.782\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 24796 | Walltime = 182.034\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 24908 | Walltime = 183.034\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 25024 | Walltime = 184.034\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 25184 | Walltime = 185.037\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.712 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 191 | Select Action Duration Sec = 0.002 | Steps = 26292 | Steps Per Second = 134.701\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 25347 | Walltime = 186.037\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 25522 | Walltime = 187.042\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 25699 | Walltime = 188.046\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.886 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 192 | Select Action Duration Sec = 0.001 | Steps = 26792 | Steps Per Second = 173.270\n",
      "INFO:root:[Learner] Loss = 0.019 | Steps = 25871 | Walltime = 189.049\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 26045 | Walltime = 190.053\n",
      "INFO:root:[Learner] Loss = 0.003 | Steps = 26211 | Walltime = 191.057\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.903 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 193 | Select Action Duration Sec = 0.001 | Steps = 27292 | Steps Per Second = 172.225\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 26388 | Walltime = 192.059\n",
      "INFO:root:[Learner] Loss = 0.044 | Steps = 26571 | Walltime = 193.062\n",
      "INFO:root:[Learner] Loss = 0.035 | Steps = 26747 | Walltime = 194.063\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.242 | Episode Length = 400 | Episode Return = 400.0 | Episodes = 195 | Select Action Duration Sec = 0.001 | Steps = 27756 | Steps Per Second = 178.403\n",
      "INFO:root:[Learner] Loss = 0.223 | Steps = 26879 | Walltime = 195.067\n",
      "INFO:root:[Learner] Loss = 0.258 | Steps = 27000 | Walltime = 196.069\n",
      "INFO:root:[Learner] Loss = 0.115 | Steps = 27114 | Walltime = 197.075\n",
      "INFO:root:[Learner] Loss = 0.091 | Steps = 27230 | Walltime = 198.081\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.205 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 196 | Select Action Duration Sec = 0.002 | Steps = 28256 | Steps Per Second = 118.922\n",
      "INFO:root:[Learner] Loss = 0.156 | Steps = 27338 | Walltime = 199.083\n",
      "INFO:root:[Learner] Loss = 0.234 | Steps = 27450 | Walltime = 200.093\n",
      "INFO:root:[Learner] Loss = 0.107 | Steps = 27567 | Walltime = 201.099\n",
      "INFO:root:[Learner] Loss = 0.082 | Steps = 27688 | Walltime = 202.099\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.350 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 197 | Select Action Duration Sec = 0.002 | Steps = 28756 | Steps Per Second = 114.958\n",
      "INFO:root:[Learner] Loss = 0.045 | Steps = 27807 | Walltime = 203.101\n",
      "INFO:root:[Learner] Loss = 0.054 | Steps = 27927 | Walltime = 204.106\n",
      "INFO:root:[Learner] Loss = 0.029 | Steps = 28088 | Walltime = 205.106\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.371 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 198 | Select Action Duration Sec = 0.001 | Steps = 29256 | Steps Per Second = 148.326\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 28263 | Walltime = 206.110\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.007 | Episode Length = 173 | Episode Return = 173.0 | Episodes = 199 | Select Action Duration Sec = 0.001 | Steps = 29429 | Steps Per Second = 171.836\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 28435 | Walltime = 207.111\n",
      "INFO:root:[Learner] Loss = 0.854 | Steps = 28613 | Walltime = 208.112\n",
      "INFO:root:[Learner] Loss = 0.601 | Steps = 28723 | Walltime = 209.114\n",
      "INFO:root:[Learner] Loss = 0.502 | Steps = 28875 | Walltime = 210.117\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.205 | Episode Length = 468 | Episode Return = 468.0 | Episodes = 200 | Select Action Duration Sec = 0.001 | Steps = 29897 | Steps Per Second = 146.020\n",
      "INFO:root:[Learner] Loss = 0.556 | Steps = 29016 | Walltime = 211.121\n",
      "INFO:root:[Learner] Loss = 0.841 | Steps = 29171 | Walltime = 212.127\n",
      "INFO:root:[Learner] Loss = 0.921 | Steps = 29315 | Walltime = 213.132\n",
      "INFO:root:[Learner] Loss = 1.056 | Steps = 29460 | Walltime = 214.136\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.852 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 205 | Select Action Duration Sec = 0.002 | Steps = 30535 | Steps Per Second = 129.803\n",
      "INFO:root:[Learner] Loss = 1.167 | Steps = 29537 | Walltime = 215.141\n",
      "INFO:root:[Learner] Loss = 0.520 | Steps = 29626 | Walltime = 216.144\n",
      "INFO:root:[Learner] Loss = 1.086 | Steps = 29724 | Walltime = 217.144\n",
      "INFO:root:[Learner] Loss = 1.436 | Steps = 29814 | Walltime = 218.146\n",
      "INFO:root:[Learner] Loss = 0.595 | Steps = 29928 | Walltime = 219.153\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.947 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 206 | Select Action Duration Sec = 0.002 | Steps = 31035 | Steps Per Second = 101.087\n",
      "INFO:root:[Learner] Loss = 0.105 | Steps = 30047 | Walltime = 220.157\n",
      "INFO:root:[Learner] Loss = 0.049 | Steps = 30161 | Walltime = 221.160\n",
      "INFO:root:[Learner] Loss = 0.039 | Steps = 30280 | Walltime = 222.164\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 30397 | Walltime = 223.167\n",
      "INFO:root:[Learner] Loss = 0.025 | Steps = 30514 | Walltime = 224.174\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.301 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 207 | Select Action Duration Sec = 0.002 | Steps = 31535 | Steps Per Second = 116.267\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 30629 | Walltime = 225.179\n",
      "INFO:root:[Learner] Loss = 0.011 | Steps = 30748 | Walltime = 226.179\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 30914 | Walltime = 227.180\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.492 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 208 | Select Action Duration Sec = 0.002 | Steps = 32035 | Steps Per Second = 143.196\n",
      "INFO:root:[Learner] Loss = 0.064 | Steps = 31091 | Walltime = 228.182\n",
      "INFO:root:[Learner] Loss = 0.171 | Steps = 31267 | Walltime = 229.186\n",
      "INFO:root:[Learner] Loss = 0.016 | Steps = 31444 | Walltime = 230.191\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.832 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 209 | Select Action Duration Sec = 0.001 | Steps = 32535 | Steps Per Second = 176.553\n",
      "INFO:root:[Learner] Loss = 0.027 | Steps = 31627 | Walltime = 231.193\n",
      "INFO:root:[Learner] Loss = 0.026 | Steps = 31801 | Walltime = 232.195\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 31970 | Walltime = 233.200\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.884 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 210 | Select Action Duration Sec = 0.001 | Steps = 33035 | Steps Per Second = 173.362\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 32139 | Walltime = 234.204\n",
      "INFO:root:[Learner] Loss = 0.052 | Steps = 32318 | Walltime = 235.209\n",
      "INFO:root:[Learner] Loss = 0.074 | Steps = 32499 | Walltime = 236.209\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.943 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 211 | Select Action Duration Sec = 0.001 | Steps = 33535 | Steps Per Second = 169.933\n",
      "INFO:root:[Learner] Loss = 0.031 | Steps = 32617 | Walltime = 237.217\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 32735 | Walltime = 238.218\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 32848 | Walltime = 239.220\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 32969 | Walltime = 240.224\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.286 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 212 | Select Action Duration Sec = 0.002 | Steps = 34035 | Steps Per Second = 116.659\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 33078 | Walltime = 241.233\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 33191 | Walltime = 242.238\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 33307 | Walltime = 243.246\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 33424 | Walltime = 244.247\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.363 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 213 | Select Action Duration Sec = 0.002 | Steps = 34535 | Steps Per Second = 114.610\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 33542 | Walltime = 245.253\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 33664 | Walltime = 246.258\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.560 | Episode Length = 197 | Episode Return = 197.0 | Episodes = 214 | Select Action Duration Sec = 0.002 | Steps = 34732 | Steps Per Second = 126.293\n",
      "INFO:root:[Learner] Loss = 0.093 | Steps = 33821 | Walltime = 247.264\n",
      "INFO:root:[Learner] Loss = 0.544 | Steps = 34003 | Walltime = 248.265\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.920 | Episode Length = 172 | Episode Return = 172.0 | Episodes = 217 | Select Action Duration Sec = 0.001 | Steps = 35059 | Steps Per Second = 186.979\n",
      "INFO:root:[Learner] Loss = 1.431 | Steps = 34186 | Walltime = 249.270\n",
      "INFO:root:[Learner] Loss = 1.642 | Steps = 34375 | Walltime = 250.271\n",
      "INFO:root:[Learner] Loss = 1.178 | Steps = 34553 | Walltime = 251.276\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.749 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 218 | Select Action Duration Sec = 0.001 | Steps = 35559 | Steps Per Second = 181.915\n",
      "INFO:root:[Learner] Loss = 0.603 | Steps = 34730 | Walltime = 252.282\n",
      "INFO:root:[Learner] Loss = 0.510 | Steps = 34914 | Walltime = 253.284\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.806 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 219 | Select Action Duration Sec = 0.001 | Steps = 36059 | Steps Per Second = 178.201\n",
      "INFO:root:[Learner] Loss = 0.112 | Steps = 35086 | Walltime = 254.286\n",
      "INFO:root:[Learner] Loss = 0.019 | Steps = 35275 | Walltime = 255.290\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 35462 | Walltime = 256.294\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.925 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 220 | Select Action Duration Sec = 0.001 | Steps = 36559 | Steps Per Second = 170.949\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 35589 | Walltime = 257.298\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 35707 | Walltime = 258.301\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 35833 | Walltime = 259.303\n",
      "INFO:root:[Learner] Loss = 0.029 | Steps = 35955 | Walltime = 260.304\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.118 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 221 | Select Action Duration Sec = 0.002 | Steps = 37059 | Steps Per Second = 121.435\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 36073 | Walltime = 261.308\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 36192 | Walltime = 262.319\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 36311 | Walltime = 263.323\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 36428 | Walltime = 264.324\n",
      "INFO:root:[Learner] Loss = 0.060 | Steps = 36543 | Walltime = 265.326\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.277 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 222 | Select Action Duration Sec = 0.002 | Steps = 37559 | Steps Per Second = 116.901\n",
      "INFO:root:[Learner] Loss = 0.059 | Steps = 36656 | Walltime = 266.334\n",
      "INFO:root:[Learner] Loss = 0.013 | Steps = 36817 | Walltime = 267.338\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 37004 | Walltime = 268.341\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.165 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 223 | Select Action Duration Sec = 0.001 | Steps = 38059 | Steps Per Second = 158.019\n",
      "INFO:root:[Learner] Loss = 0.019 | Steps = 37175 | Walltime = 269.341\n",
      "INFO:root:[Learner] Loss = 0.025 | Steps = 37353 | Walltime = 270.343\n",
      "INFO:root:[Learner] Loss = 0.036 | Steps = 37525 | Walltime = 271.347\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.901 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 224 | Select Action Duration Sec = 0.001 | Steps = 38559 | Steps Per Second = 172.373\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 37701 | Walltime = 272.349\n",
      "INFO:root:[Learner] Loss = 0.031 | Steps = 37880 | Walltime = 273.350\n",
      "INFO:root:[Learner] Loss = 0.046 | Steps = 38052 | Walltime = 274.353\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.868 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 225 | Select Action Duration Sec = 0.001 | Steps = 39059 | Steps Per Second = 174.335\n",
      "INFO:root:[Learner] Loss = 0.076 | Steps = 38227 | Walltime = 275.356\n",
      "INFO:root:[Learner] Loss = 0.077 | Steps = 38406 | Walltime = 276.360\n",
      "INFO:root:[Learner] Loss = 0.085 | Steps = 38541 | Walltime = 277.365\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.118 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 226 | Select Action Duration Sec = 0.001 | Steps = 39559 | Steps Per Second = 160.366\n",
      "INFO:root:[Learner] Loss = 0.027 | Steps = 38662 | Walltime = 278.367\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 38784 | Walltime = 279.370\n",
      "INFO:root:[Learner] Loss = 0.064 | Steps = 38901 | Walltime = 280.376\n",
      "INFO:root:[Learner] Loss = 0.027 | Steps = 39018 | Walltime = 281.383\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.189 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 227 | Select Action Duration Sec = 0.002 | Steps = 40059 | Steps Per Second = 119.360\n",
      "INFO:root:[Learner] Loss = 0.068 | Steps = 39141 | Walltime = 282.383\n",
      "INFO:root:[Learner] Loss = 0.049 | Steps = 39260 | Walltime = 283.385\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.710 | Episode Length = 207 | Episode Return = 207.0 | Episodes = 228 | Select Action Duration Sec = 0.002 | Steps = 40266 | Steps Per Second = 121.058\n",
      "INFO:root:[Learner] Loss = 0.072 | Steps = 39378 | Walltime = 284.386\n",
      "INFO:root:[Learner] Loss = 0.284 | Steps = 39499 | Walltime = 285.396\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.698 | Episode Length = 318 | Episode Return = 318.0 | Episodes = 229 | Select Action Duration Sec = 0.002 | Steps = 40584 | Steps Per Second = 117.859\n",
      "INFO:root:[Learner] Loss = 0.692 | Steps = 39611 | Walltime = 286.397\n",
      "INFO:root:[Learner] Loss = 1.363 | Steps = 39749 | Walltime = 287.402\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.925 | Episode Length = 146 | Episode Return = 146.0 | Episodes = 231 | Select Action Duration Sec = 0.001 | Steps = 40810 | Steps Per Second = 157.926\n",
      "INFO:root:[Learner] Loss = 0.953 | Steps = 39916 | Walltime = 288.403\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.893 | Episode Length = 162 | Episode Return = 162.0 | Episodes = 233 | Select Action Duration Sec = 0.001 | Steps = 41072 | Steps Per Second = 181.488\n",
      "INFO:root:[Learner] Loss = 1.126 | Steps = 40098 | Walltime = 289.405\n",
      "INFO:root:[Learner] Loss = 1.161 | Steps = 40283 | Walltime = 290.409\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.023 | Episode Length = 187 | Episode Return = 187.0 | Episodes = 235 | Select Action Duration Sec = 0.001 | Steps = 41360 | Steps Per Second = 182.754\n",
      "INFO:root:[Learner] Loss = 0.566 | Steps = 40451 | Walltime = 291.415\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.743 | Episode Length = 129 | Episode Return = 129.0 | Episodes = 237 | Select Action Duration Sec = 0.001 | Steps = 41611 | Steps Per Second = 173.705\n",
      "INFO:root:[Learner] Loss = 0.279 | Steps = 40622 | Walltime = 292.417\n",
      "INFO:root:[Learner] Loss = 0.168 | Steps = 40795 | Walltime = 293.421\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.962 | Episode Length = 162 | Episode Return = 162.0 | Episodes = 239 | Select Action Duration Sec = 0.001 | Steps = 41906 | Steps Per Second = 168.485\n",
      "INFO:root:[Learner] Loss = 0.069 | Steps = 40959 | Walltime = 294.421\n",
      "INFO:root:[Learner] Loss = 0.072 | Steps = 41134 | Walltime = 295.422\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.989 | Episode Length = 175 | Episode Return = 175.0 | Episodes = 241 | Select Action Duration Sec = 0.001 | Steps = 42229 | Steps Per Second = 176.961\n",
      "INFO:root:[Learner] Loss = 0.092 | Steps = 41304 | Walltime = 296.427\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.910 | Episode Length = 145 | Episode Return = 145.0 | Episodes = 243 | Select Action Duration Sec = 0.001 | Steps = 42442 | Steps Per Second = 159.357\n",
      "INFO:root:[Learner] Loss = 0.519 | Steps = 41457 | Walltime = 297.427\n",
      "INFO:root:[Learner] Loss = 0.094 | Steps = 41574 | Walltime = 298.433\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.183 | Episode Length = 142 | Episode Return = 142.0 | Episodes = 245 | Select Action Duration Sec = 0.002 | Steps = 42662 | Steps Per Second = 120.006\n",
      "INFO:root:[Learner] Loss = 0.189 | Steps = 41694 | Walltime = 299.439\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.221 | Episode Length = 147 | Episode Return = 147.0 | Episodes = 246 | Select Action Duration Sec = 0.002 | Steps = 42809 | Steps Per Second = 120.450\n",
      "INFO:root:[Learner] Loss = 0.090 | Steps = 41813 | Walltime = 300.440\n",
      "INFO:root:[Learner] Loss = 0.157 | Steps = 41922 | Walltime = 301.447\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.234 | Episode Length = 133 | Episode Return = 133.0 | Episodes = 247 | Select Action Duration Sec = 0.002 | Steps = 42942 | Steps Per Second = 107.766\n",
      "INFO:root:[Learner] Loss = 0.092 | Steps = 42036 | Walltime = 302.455\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.113 | Episode Length = 128 | Episode Return = 128.0 | Episodes = 248 | Select Action Duration Sec = 0.002 | Steps = 43070 | Steps Per Second = 114.986\n",
      "INFO:root:[Learner] Loss = 0.148 | Steps = 42154 | Walltime = 303.456\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.239 | Episode Length = 147 | Episode Return = 147.0 | Episodes = 249 | Select Action Duration Sec = 0.002 | Steps = 43217 | Steps Per Second = 118.709\n",
      "INFO:root:[Learner] Loss = 0.226 | Steps = 42271 | Walltime = 304.461\n",
      "INFO:root:[Learner] Loss = 0.219 | Steps = 42387 | Walltime = 305.463\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.227 | Episode Length = 142 | Episode Return = 142.0 | Episodes = 251 | Select Action Duration Sec = 0.002 | Steps = 43428 | Steps Per Second = 115.764\n",
      "INFO:root:[Learner] Loss = 0.329 | Steps = 42503 | Walltime = 306.466\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.049 | Episode Length = 123 | Episode Return = 123.0 | Episodes = 252 | Select Action Duration Sec = 0.002 | Steps = 43551 | Steps Per Second = 117.299\n",
      "INFO:root:[Learner] Loss = 0.070 | Steps = 42622 | Walltime = 307.471\n",
      "INFO:root:[Learner] Loss = 0.290 | Steps = 42797 | Walltime = 308.473\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.881 | Episode Length = 150 | Episode Return = 150.0 | Episodes = 254 | Select Action Duration Sec = 0.001 | Steps = 43827 | Steps Per Second = 170.245\n",
      "INFO:root:[Learner] Loss = 0.356 | Steps = 42964 | Walltime = 309.474\n",
      "INFO:root:[Learner] Loss = 0.153 | Steps = 43132 | Walltime = 310.477\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.023 | Episode Length = 175 | Episode Return = 175.0 | Episodes = 256 | Select Action Duration Sec = 0.001 | Steps = 44160 | Steps Per Second = 171.120\n",
      "INFO:root:[Learner] Loss = 0.145 | Steps = 43296 | Walltime = 311.477\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.019 | Episode Length = 164 | Episode Return = 164.0 | Episodes = 257 | Select Action Duration Sec = 0.001 | Steps = 44324 | Steps Per Second = 161.027\n",
      "INFO:root:[Learner] Loss = 0.064 | Steps = 43460 | Walltime = 312.479\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.431 | Episode Length = 73 | Episode Return = 73.0 | Episodes = 259 | Select Action Duration Sec = 0.001 | Steps = 44564 | Steps Per Second = 169.499\n",
      "INFO:root:[Learner] Loss = 0.052 | Steps = 43626 | Walltime = 313.480\n",
      "INFO:root:[Learner] Loss = 0.239 | Steps = 43800 | Walltime = 314.484\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.163 | Episode Length = 370 | Episode Return = 370.0 | Episodes = 260 | Select Action Duration Sec = 0.001 | Steps = 44934 | Steps Per Second = 171.105\n",
      "INFO:root:[Learner] Loss = 0.343 | Steps = 43972 | Walltime = 315.485\n",
      "INFO:root:[Learner] Loss = 0.306 | Steps = 44149 | Walltime = 316.485\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.122 | Episode Length = 196 | Episode Return = 196.0 | Episodes = 262 | Select Action Duration Sec = 0.001 | Steps = 45274 | Steps Per Second = 174.730\n",
      "INFO:root:[Learner] Loss = 0.175 | Steps = 44319 | Walltime = 317.487\n",
      "INFO:root:[Learner] Loss = 0.366 | Steps = 44426 | Walltime = 318.488\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.086 | Episode Length = 243 | Episode Return = 243.0 | Episodes = 263 | Select Action Duration Sec = 0.002 | Steps = 45517 | Steps Per Second = 116.493\n",
      "INFO:root:[Learner] Loss = 0.188 | Steps = 44541 | Walltime = 319.490\n",
      "INFO:root:[Learner] Loss = 0.124 | Steps = 44659 | Walltime = 320.490\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.881 | Episode Length = 220 | Episode Return = 220.0 | Episodes = 264 | Select Action Duration Sec = 0.002 | Steps = 45737 | Steps Per Second = 116.976\n",
      "INFO:root:[Learner] Loss = 0.153 | Steps = 44774 | Walltime = 321.501\n",
      "INFO:root:[Learner] Loss = 0.125 | Steps = 44891 | Walltime = 322.505\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.042 | Episode Length = 241 | Episode Return = 241.0 | Episodes = 265 | Select Action Duration Sec = 0.002 | Steps = 45978 | Steps Per Second = 118.029\n",
      "INFO:root:[Learner] Loss = 0.182 | Steps = 45011 | Walltime = 323.507\n",
      "INFO:root:[Learner] Loss = 0.181 | Steps = 45129 | Walltime = 324.513\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.994 | Episode Length = 232 | Episode Return = 232.0 | Episodes = 266 | Select Action Duration Sec = 0.002 | Steps = 46210 | Steps Per Second = 116.340\n",
      "INFO:root:[Learner] Loss = 0.149 | Steps = 45245 | Walltime = 325.521\n",
      "INFO:root:[Learner] Loss = 0.047 | Steps = 45361 | Walltime = 326.528\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.598 | Episode Length = 185 | Episode Return = 185.0 | Episodes = 267 | Select Action Duration Sec = 0.002 | Steps = 46395 | Steps Per Second = 115.811\n",
      "INFO:root:[Learner] Loss = 0.038 | Steps = 45480 | Walltime = 327.532\n",
      "INFO:root:[Learner] Loss = 0.038 | Steps = 45633 | Walltime = 328.534\n",
      "INFO:root:[Learner] Loss = 0.049 | Steps = 45804 | Walltime = 329.534\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.264 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 268 | Select Action Duration Sec = 0.001 | Steps = 46895 | Steps Per Second = 153.178\n",
      "INFO:root:[Learner] Loss = 0.073 | Steps = 45970 | Walltime = 330.538\n",
      "INFO:root:[Learner] Loss = 0.093 | Steps = 46138 | Walltime = 331.538\n",
      "INFO:root:[Learner] Loss = 0.102 | Steps = 46310 | Walltime = 332.541\n",
      "INFO:root:[Learner] Loss = 0.182 | Steps = 46476 | Walltime = 333.544\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.977 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 270 | Select Action Duration Sec = 0.001 | Steps = 47529 | Steps Per Second = 167.961\n",
      "INFO:root:[Learner] Loss = 0.055 | Steps = 46637 | Walltime = 334.545\n",
      "INFO:root:[Learner] Loss = 0.164 | Steps = 46811 | Walltime = 335.548\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 46983 | Walltime = 336.553\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.949 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 271 | Select Action Duration Sec = 0.001 | Steps = 48029 | Steps Per Second = 169.586\n",
      "INFO:root:[Learner] Loss = 0.017 | Steps = 47153 | Walltime = 337.554\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 47290 | Walltime = 338.559\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 47412 | Walltime = 339.565\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 47527 | Walltime = 340.571\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.778 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 272 | Select Action Duration Sec = 0.002 | Steps = 48529 | Steps Per Second = 132.366\n",
      "INFO:root:[Learner] Loss = 0.025 | Steps = 47640 | Walltime = 341.573\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 47760 | Walltime = 342.573\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 47878 | Walltime = 343.580\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 47997 | Walltime = 344.586\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.270 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 273 | Select Action Duration Sec = 0.002 | Steps = 49029 | Steps Per Second = 117.126\n",
      "INFO:root:[Learner] Loss = 0.020 | Steps = 48113 | Walltime = 345.588\n",
      "INFO:root:[Learner] Loss = 0.002 | Steps = 48232 | Walltime = 346.590\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 48350 | Walltime = 347.592\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 48482 | Walltime = 348.597\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.001 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 274 | Select Action Duration Sec = 0.002 | Steps = 49529 | Steps Per Second = 124.973\n",
      "INFO:root:[Learner] Loss = 0.003 | Steps = 48646 | Walltime = 349.601\n",
      "INFO:root:[Learner] Loss = 0.005 | Steps = 48822 | Walltime = 350.604\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 48999 | Walltime = 351.605\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.001 | Env Step Duration Sec = 0.000 | Episode Duration = 2.902 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 275 | Select Action Duration Sec = 0.001 | Steps = 50029 | Steps Per Second = 172.329\n",
      "INFO:root:[Learner] Loss = 0.003 | Steps = 49170 | Walltime = 352.605\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 49347 | Walltime = 353.610\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 49521 | Walltime = 354.613\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.873 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 276 | Select Action Duration Sec = 0.001 | Steps = 50529 | Steps Per Second = 174.057\n",
      "INFO:root:[Learner] Loss = 0.004 | Steps = 49698 | Walltime = 355.618\n",
      "INFO:root:[Learner] Loss = 0.022 | Steps = 49872 | Walltime = 356.620\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.854 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 277 | Select Action Duration Sec = 0.001 | Steps = 51029 | Steps Per Second = 175.205\n",
      "INFO:root:[Learner] Loss = 0.024 | Steps = 50045 | Walltime = 357.624\n",
      "INFO:root:[Learner] Loss = 0.010 | Steps = 50189 | Walltime = 358.625\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.001 | Env Step Duration Sec = 0.000 | Episode Duration = 1.734 | Episode Length = 233 | Episode Return = 233.0 | Episodes = 278 | Select Action Duration Sec = 0.002 | Steps = 51262 | Steps Per Second = 134.387\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 50308 | Walltime = 359.629\n",
      "INFO:root:[Learner] Loss = 0.166 | Steps = 50429 | Walltime = 360.635\n",
      "INFO:root:[Learner] Loss = 0.342 | Steps = 50542 | Walltime = 361.642\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.421 | Episode Length = 283 | Episode Return = 283.0 | Episodes = 279 | Select Action Duration Sec = 0.002 | Steps = 51545 | Steps Per Second = 116.905\n",
      "INFO:root:[Learner] Loss = 0.074 | Steps = 50652 | Walltime = 362.646\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.622 | Episode Length = 75 | Episode Return = 75.0 | Episodes = 282 | Select Action Duration Sec = 0.002 | Steps = 51707 | Steps Per Second = 120.525\n",
      "INFO:root:[Learner] Loss = 0.281 | Steps = 50770 | Walltime = 363.648\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.226 | Episode Length = 138 | Episode Return = 138.0 | Episodes = 283 | Select Action Duration Sec = 0.002 | Steps = 51845 | Steps Per Second = 112.538\n",
      "INFO:root:[Learner] Loss = 0.755 | Steps = 50883 | Walltime = 364.655\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.199 | Episode Length = 144 | Episode Return = 144.0 | Episodes = 284 | Select Action Duration Sec = 0.002 | Steps = 51989 | Steps Per Second = 120.167\n",
      "INFO:root:[Learner] Loss = 0.671 | Steps = 51003 | Walltime = 365.661\n",
      "INFO:root:[Learner] Loss = 0.491 | Steps = 51120 | Walltime = 366.662\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.466 | Episode Length = 172 | Episode Return = 172.0 | Episodes = 285 | Select Action Duration Sec = 0.002 | Steps = 52161 | Steps Per Second = 117.331\n",
      "INFO:root:[Learner] Loss = 0.680 | Steps = 51241 | Walltime = 367.672\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.330 | Episode Length = 159 | Episode Return = 159.0 | Episodes = 286 | Select Action Duration Sec = 0.002 | Steps = 52320 | Steps Per Second = 119.528\n",
      "INFO:root:[Learner] Loss = 0.528 | Steps = 51362 | Walltime = 368.675\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.193 | Episode Length = 195 | Episode Return = 195.0 | Episodes = 287 | Select Action Duration Sec = 0.001 | Steps = 52515 | Steps Per Second = 163.415\n",
      "INFO:root:[Learner] Loss = 0.429 | Steps = 51539 | Walltime = 369.678\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.573 | Episode Length = 99 | Episode Return = 99.0 | Episodes = 289 | Select Action Duration Sec = 0.001 | Steps = 52695 | Steps Per Second = 172.743\n",
      "INFO:root:[Learner] Loss = 0.209 | Steps = 51714 | Walltime = 370.681\n",
      "INFO:root:[Learner] Loss = 0.190 | Steps = 51888 | Walltime = 371.686\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 1.058 | Episode Length = 172 | Episode Return = 172.0 | Episodes = 291 | Select Action Duration Sec = 0.001 | Steps = 53015 | Steps Per Second = 162.616\n",
      "INFO:root:[Learner] Loss = 0.131 | Steps = 52054 | Walltime = 372.689\n",
      "INFO:root:[Learner] Loss = 0.195 | Steps = 52222 | Walltime = 373.693\n",
      "INFO:root:[Learner] Loss = 0.203 | Steps = 52395 | Walltime = 374.695\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.902 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 292 | Select Action Duration Sec = 0.001 | Steps = 53515 | Steps Per Second = 172.319\n",
      "INFO:root:[Learner] Loss = 0.337 | Steps = 52573 | Walltime = 375.696\n",
      "INFO:root:[Learner] Loss = 0.204 | Steps = 52755 | Walltime = 376.701\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 0.930 | Episode Length = 166 | Episode Return = 166.0 | Episodes = 294 | Select Action Duration Sec = 0.001 | Steps = 53830 | Steps Per Second = 178.586\n",
      "INFO:root:[Learner] Loss = 0.065 | Steps = 52927 | Walltime = 377.706\n",
      "INFO:root:[Learner] Loss = 0.061 | Steps = 53100 | Walltime = 378.713\n",
      "INFO:root:[Learner] Loss = 0.027 | Steps = 53221 | Walltime = 379.715\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 3.434 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 295 | Select Action Duration Sec = 0.001 | Steps = 54330 | Steps Per Second = 145.612\n",
      "INFO:root:[Learner] Loss = 0.021 | Steps = 53347 | Walltime = 380.731\n",
      "INFO:root:[Learner] Loss = 0.041 | Steps = 53463 | Walltime = 381.738\n",
      "INFO:root:[Learner] Loss = 0.018 | Steps = 53583 | Walltime = 382.738\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 53705 | Walltime = 383.747\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 53822 | Walltime = 384.751\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.271 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 296 | Select Action Duration Sec = 0.002 | Steps = 54830 | Steps Per Second = 117.071\n",
      "INFO:root:[Learner] Loss = 0.009 | Steps = 53941 | Walltime = 385.756\n",
      "INFO:root:[Learner] Loss = 0.007 | Steps = 54061 | Walltime = 386.757\n",
      "INFO:root:[Learner] Loss = 0.006 | Steps = 54184 | Walltime = 387.763\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 54307 | Walltime = 388.766\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 4.120 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 297 | Select Action Duration Sec = 0.002 | Steps = 55330 | Steps Per Second = 121.377\n",
      "INFO:root:[Learner] Loss = 0.020 | Steps = 54465 | Walltime = 389.771\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 54655 | Walltime = 390.773\n",
      "INFO:root:[Learner] Loss = 0.014 | Steps = 54831 | Walltime = 391.779\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.797 | Episode Length = 500 | Episode Return = 500.0 | Episodes = 298 | Select Action Duration Sec = 0.001 | Steps = 55830 | Steps Per Second = 178.769\n",
      "INFO:root:[Learner] Loss = 0.008 | Steps = 55014 | Walltime = 392.782\n",
      "INFO:root:[Learner] Loss = 0.012 | Steps = 55196 | Walltime = 393.787\n",
      "INFO:root:[Environment Loop] Env Reset Duration Sec = 0.000 | Env Step Duration Sec = 0.000 | Episode Duration = 2.173 | Episode Length = 395 | Episode Return = 395.0 | Episodes = 299 | Select Action Duration Sec = 0.001 | Steps = 56225 | Steps Per Second = 181.783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56337"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_environment()\n",
    "env_spec = acme.make_environment_spec(env)\n",
    "\n",
    "network = snt.Sequential([\n",
    "      snt.Flatten(),\n",
    "      snt.nets.MLP([50, 50, env_spec.actions.num_values]),\n",
    "  ])\n",
    "\n",
    "agent = dqn.DQN(env_spec, network,\n",
    "               epsilon=0.1,\n",
    "               learning_rate=1e-3,\n",
    "               max_replay_size=1_000,\n",
    "               batch_size=32)\n",
    "\n",
    "# logger = loggers.TerminalLogger(time_delta=0.5)\n",
    "env_loop = acme.EnvironmentLoop(env, agent)\n",
    "env_loop.run(num_episodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDjaFyTiOFXc",
    "outputId": "908c350a-920e-4496-dd33-27b162bd4fce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment CartPole-v1 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = make_environment(record=True)\n",
    "\n",
    "timestep = env.reset()\n",
    "\n",
    "while not timestep.last():\n",
    "  action = agent.select_action(timestep.observation)\n",
    "  timestep = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "AdnfTJeVSjkx",
    "outputId": "8c3ea3e8-cfa3-4020-ad01-2f76823d11de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"/content/video/rl-video-episode-0.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHboMz9cY0R_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
